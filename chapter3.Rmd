# Chapter 3: Logistic Regression

## Data analysis
### 2. Reading the data and description of the dataset
For this we have to include the library *dplyr* (```library(dplyr)```) which is a common R library used for data wrangling
```{r,message=FALSE}
library(dplyr)
```
```{r}
alc <- read.csv("./data/alc.csv")

```
To get an overview on the dataset, let's print out the names of the variables.
Description of the data set:
```{r}
colnames(alc)
```

### 3. Relation of different values to high/low alcohol consumption
Choose 4 interesting variables from the data and formulate hypothesis towards their relationship with alcohol consumption

**Hypothesis 1**: *sex*: There is a statistical difference concerning sex: Males are more likely to have a high alcohol consumption.

**Hypothesis 2** *failure*: Number of past class failures has a relation to alcohol consumption.

**Hypothesis 3** *famrel*: Good family relationships make high alcohol consume less likely.

**Hypothesis 4** *goout*: The frequency of going out with friends will affect the alcohol consumption.


### 4. Numerical and graphical exploration of chosen variables
distributions (cross-tabulations, bar plots, box plots), comment on findings, comparison to hypotheses
```{r}
#library(tidyr); library(dplyr); library(ggplot2)
# draw a bar plot of each variable
#gather(alc) %>% ggplot(aes(value)) + facet_wrap("key", scales = "free") + geom_bar()
```
**Hypothesis 1: gender and alcoholic consumption**
```{r}
alc %>% group_by(sex, high_use) %>% summarise(count=n())
```
This is supporting **Hypothesis 1**. Whereas `r (42/198)*100`% of the female students mention a high alcohol consumption, `r (72/184)*100`% 
of the male students have a high use, which is almost the double value. To look at this graphically, let's look at a bar plot.
```{r}
library(ggplot2)
g2 <- ggplot(alc, aes(x = high_use, col=sex))
g2 + geom_bar()
```

The bar plot shows quite clearly, that the difference between high-use and no high-use are quite different for male and female students.

**Hypothesis 2 - failures**: Let's now investigate if one can see a clear relation between the failures and the alcohol consumption.
```{r}
alc %>% group_by(high_use) %>% summarise(count=n())
alc %>% group_by(failures) %>% summarise(count=n())
alc %>% group_by(high_use, failures) %>% summarise(count=n())
alc %>% group_by(high_use, failures>0) %>% summarise(count=n())
```
As one can see, 5 of the `r 268+114` students have experienced 4 failures. From these 5, three report high alcohol consumption. This sample might however be to small to judge if a real relationship exist. Let's look at more 2 or 3 failures and create a bar plot for this. 
```{r}

g3 <- ggplot(alc, aes(x=failures, col=high_use))
g3 + geom_bar()

g4 <- ggplot(alc, aes(x = sex, y = alc_use, col=failures>0))
g4 + geom_boxplot()
```

Looking at the bar plot, one might at least come to the conclusion, that having experienced no failure makes it less likely to become addicted to high alcoholic consumption. However, the sample for having a failure is much less than for having none.
It might make more sense to combine the numbers for failures > 1 together. Now, a box plot gives a nice visualisation of how having experienced at least 1 failure can impact the alcoholic consumption.
Again, the impact seems to be much higher for the mail students.

**Hypothesis 3 - Family**: 
```{r}
alc %>% group_by(famrel,high_use) %>% summarise(count=n())
```

```{r}
g5 <- ggplot(alc, aes(x = high_use, y = famrel))
g5 + geom_boxplot() + ylab("quality of family relationships (from 1 - very bad to 5 - excellent)")

g6 <- ggplot(alc, aes(x=famrel, col=high_use))
g6 + geom_bar()
```

Both the box plot as well as the bar plot seem to at least give a trend on the correctness of the hypothesis: Whereas the mean value for the quality of the family relationships is at 3.5 for people stating a high alcohol consumption, it has a better mean quality (4.5) for students without hinting at alcohol problems. The bar plot gives a bit more clearer view on the diferrent family relationship bins. The high-use fraction is getting more for famrel=2 or 3 than for 4 and 5. For famrel=1 the sample is probably to small to judge.

**Hypothesis 4 - going out**
```{r}
alc %>% group_by(goout,high_use) %>% summarise(count=n())
```

```{r}
g7 <- ggplot(alc, aes(x = high_use, y = goout, col=sex))
g7 + geom_boxplot() + ylab("going out with friends (from 1 [very low] to 5 [very high]")

g8 <- ggplot(alc, aes(x=goout, col=high_use))
g8 + geom_bar()
```

Again, the numeric cross tabulations as well as the plots are supporting the hypothesis. Going out with friends more often (higher value) seems to have an impact on the alcohol consumption.

### 5. Logistic regression
```{r}
# find the model with glm()
m <- glm(high_use ~ sex + failures + famrel + goout, data = alc, family = "binomial")
summary(m)
```
The model summary shows a high significance for the correlation to *sexM* and *goout*, a medium significance for *famrel* und no signifant value for *failure*. One could fit the model again, dropping at least the *failure* variable. But first let's study the odds ratios (OR).
```{r}
coef(m)

# compute odds ratios (OR)
OR <- coef(m) %>% exp

# compute confidence intervals (CI)
CI <- confint(m) %>% exp

# print out the odds ratios with their confidence intervals
cbind(OR, CI)
```
The odds ratios can tell us if having a certain property (e.g. being male, going out often) can be positively or negatively associated with the logical value looked at (here high alcohol consumption). If the OR is > 0, it means it is positively associated, with < 0 it is negatively associated.

The male sex variable has the strongest relationship to the binary target variable, with an odds ratio of +2.45 - that means that the probability for a male student having high alcohol consumption is about 2.5 higher than for a female student. "going out" is also positively associated with high alcohol consumption, wheres "family relation" has a negative relation (high quality of family relation leading more likely to low alcohol consumption). These OR thus support the above-mentioned hypotheses.


### 6. Predictive power of Model
As *failures* didn't have a significant relationship according to my logistic regression model, I will drop this variable and fit the model again, print out the summary and calculate the OR and Confidence levels:

```{r}
m2 <- glm(high_use ~ sex + famrel + goout, data = alc, family = "binomial")
summary(m2)
coef(m2)
OR <- coef(m2) %>% exp
CI <- confint(m2) %>% exp
cbind(OR, CI)
```
As a next step let's check the predictive power of the new model, adding the new columns *probability* and *predictions* to the *alc* dataset. *probablities* will be calculated by using the ```predict()``` function on the model and *predictions* will defined as TRUE if the probability is higher than 50%.
```{r}
probabilities <- predict(m2, type = "response")
alc <- mutate(alc, probability = probabilities)
alc <- mutate(alc, prediction = probabilities > 0.5)
```
To see an example on how good the model is, we can print the first rows of the columns we are interested in and look at the confusion matrix:
```{r}
select(alc, sex, famrel, goout,  high_use, probability, prediction) %>% tail(10)
table(high_use = alc$high_use, prediction = alc$prediction)
```

To graphically visualize the actual values and the predictions, we can draw a plot of 'high use' vs. 'probability'.
```{r}
g <- ggplot(alc, aes(x = probability, y = high_use, col=prediction))
g + geom_point()
```

Furthermore, we can do another cross-tab of predictions vs. actual values, printing out the fractions instead and adding margins.
```{r}
table(high_use = alc$high_use, prediction = alc$prediction) %>% prop.table() %>% addmargins()
```

**Accuracy of the model**
The proportion of inaccurately classified individuals (training error) can be calculated by taking the values from the confusion matrix: 
(18+63)/(250+18+63+51) = 0.21. We will get the same value by defiing a loss function as below:
```{r}
# define a loss function (mean prediction error)
loss_func <- function(class, prob) {
  n_wrong <- abs(class - prob) > 0.5
  mean(n_wrong)
}

# call loss_func to compute the average number of wrong predictions in the (training) data
loss_func(class = alc$high_use, prob = alc$probability)
```
The loss function gives us a value of about 0.21 (as also calculated before), meaning that about 21% of the predictions will be wrong. This value is better than the value in the DataCamp example (about 26%), making this model slightly better.

### 7. Bonus: 10-fold cross-validation


### 8. Super-Bonus